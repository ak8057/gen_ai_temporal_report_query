{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b172a3cd-a8ae-4cc5-9380-bd0cf7733221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_google_genai in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (2.0.10)\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core>=0.3.75 (from langchain_google_genai)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai)\n",
      "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain_google_genai) (2.11.7)\n",
      "Requirement already satisfied: filetype<2,>=1.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langchain-core>=0.3.75->langchain_google_genai) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain_google_genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.3.0)\n",
      "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
      "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Installing collected packages: langchain-core, google-ai-generativelanguage, langchain_google_genai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.72\n",
      "    Uninstalling langchain-core-0.3.72:\n",
      "      Successfully uninstalled langchain-core-0.3.72\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "  Attempting uninstall: langchain_google_genai\n",
      "    Found existing installation: langchain-google-genai 2.0.10\n",
      "    Uninstalling langchain-google-genai-2.0.10:\n",
      "      Successfully uninstalled langchain-google-genai-2.0.10\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.7.0 langchain-core-0.3.76 langchain_google_genai-2.1.12\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/abhaykumar/codeit/projects/samsungPrism/venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de677643-24ab-48d8-8d60-7b0cecb0e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /Users/abhaykumar/codeit/projects/samsungPrism/venv/lib/python3.10/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/abhaykumar/codeit/projects/samsungPrism/venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c98310-fff8-4813-858a-69c1a41efb65",
   "metadata": {},
   "outputs": [],
   "source": [
    " from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "api_key = \"\"\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",  # or gemini-1.5-pro\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2529be53-4723-482b-b2c8-0b01fa68257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE customers (\n",
      "\t`customerNumber` INTEGER NOT NULL, \n",
      "\t`customerName` VARCHAR(100), \n",
      "\t`contactLastName` VARCHAR(50), \n",
      "\t`contactFirstName` VARCHAR(50), \n",
      "\tphone VARCHAR(50), \n",
      "\t`addressLine1` VARCHAR(100), \n",
      "\tcity VARCHAR(50), \n",
      "\tcountry VARCHAR(50), \n",
      "\t`creditLimit` DECIMAL(10, 2), \n",
      "\tPRIMARY KEY (`customerNumber`)\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from customers table:\n",
      "customerNumber\tcustomerName\tcontactLastName\tcontactFirstName\tphone\taddressLine1\tcity\tcountry\tcreditLimit\n",
      "101\tAtelier graphique\tSchmitt\tCarine\t40.32.2555\t54, rue Royale\tNantes\tFrance\t21000.00\n",
      "102\tSignal Gift Stores\tKing\tJean\t7025551838\t8489 Strong St.\tLas Vegas\tUSA\t71800.00\n",
      "103\tAustralian Collectors\tFerguson\tPeter\t03 9520 4555\t636 St Kilda Road\tMelbourne\tAustralia\t117300.00\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE orders (\n",
      "\t`orderNumber` INTEGER NOT NULL, \n",
      "\t`orderDate` DATE, \n",
      "\tstatus VARCHAR(20), \n",
      "\t`customerNumber` INTEGER, \n",
      "\tPRIMARY KEY (`orderNumber`), \n",
      "\tCONSTRAINT orders_ibfk_1 FOREIGN KEY(`customerNumber`) REFERENCES customers (`customerNumber`)\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from orders table:\n",
      "orderNumber\torderDate\tstatus\tcustomerNumber\n",
      "1001\t2024-06-15\tShipped\t101\n",
      "1002\t2024-06-20\tOn Hold\t102\n",
      "1003\t2024-07-01\tCancelled\t103\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE sample_adobe_feature_work_log (\n",
      "\tfeatureid VARCHAR(255), \n",
      "\tfeaturename VARCHAR(255), \n",
      "\tfeaturedescription VARCHAR(255), \n",
      "\tteam VARCHAR(255), \n",
      "\tissueid VARCHAR(255), \n",
      "\tstatus VARCHAR(255), \n",
      "\tchangedat DATETIME, \n",
      "\tassignedto VARCHAR(255), \n",
      "\tpriority VARCHAR(255)\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from sample_adobe_feature_work_log table:\n",
      "featureid\tfeaturename\tfeaturedescription\tteam\tissueid\tstatus\tchangedat\tassignedto\tpriority\n",
      "ADOBE_FTR_02\tPhotoshop Neural Filters\tPortrait retouch and style transfer tools\tExperience Design\tADOBE_FTR_02_ISSUE_01\tLogged\t2024-03-01 00:00:00\temma_rojas\tP4\n",
      "ADOBE_FTR_02\tPhotoshop Neural Filters\tPortrait retouch and style transfer tools\tExperience Design\tADOBE_FTR_02_ISSUE_02\tLogged\t2024-03-02 00:00:00\tnoah_singh\tP4\n",
      "ADOBE_FTR_02\tPhotoshop Neural Filters\tPortrait retouch and style transfer tools\tExperience Design\tADOBE_FTR_02_ISSUE_01\tDeployed\t2024-03-03 00:00:00\temma_rojas\tP4\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE sample_with_anomalies (\n",
      "\tid FLOAT, \n",
      "\tname VARCHAR(255), \n",
      "\tage FLOAT, \n",
      "\temail VARCHAR(255), \n",
      "\tjoindate VARCHAR(255), \n",
      "\tsalary FLOAT\n",
      ")COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from sample_with_anomalies table:\n",
      "id\tname\tage\temail\tjoindate\tsalary\n",
      "1.0\tAlice\t25.0\talice@example.com\t2022-01-15\t50000.0\n",
      "2.0\tBob\t-30.0\tbob[at]example.com\t2022-02-30\tNone\n",
      "None\tCharlie\t22.0\tnan\tNot a date\t45000.0\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "from langchain.utilities import SQLDatabase\n",
    "# No asyncio needed for this part\n",
    "\n",
    "# Database credentials\n",
    "user = \"root\"\n",
    "password = \"password032005\"\n",
    "host = \"localhost\"\n",
    "port = \"3307\"\n",
    "database = \"classicmodels\"\n",
    "\n",
    "# URL-encode the password\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "# Create the database connection\n",
    "db = SQLDatabase.from_uri(\n",
    "    f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database}\",\n",
    "    sample_rows_in_table_info=3\n",
    ")\n",
    "\n",
    "# --- CORRECTED CODE ---\n",
    "# This is a regular function now\n",
    "def show_table_info():\n",
    "    # Call the function without 'await'\n",
    "    info = db.get_table_info()\n",
    "    print(info)\n",
    "\n",
    "# Run the function directly\n",
    "show_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6eae0b6-de27-4093-8fbe-0e68a490a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.284\n",
      "  Using cached langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv==1.0.0\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting streamlit==1.22.0\n",
      "  Using cached streamlit-1.22.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tiktoken==0.4.0\n",
      "  Using cached tiktoken-0.4.0.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting faiss-cpu==1.7.4\n",
      "  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf~=3.19.0\n",
      "  Using cached protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Requirement already satisfied: langchain-experimental in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.3.4)\n",
      "Collecting mysql-connector-python\n",
      "  Using cached mysql_connector_python-9.4.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pymysql in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.1.0)\n",
      "Requirement already satisfied: chromadb in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.0.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain==0.0.284) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain==0.0.284) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain==0.0.284) (3.11.13)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.284)\n",
      "  Using cached dataclasses_json-0.5.9-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain==0.0.284)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain==0.0.284)\n",
      "  Using cached numexpr-2.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.0.284)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain==0.0.284) (2.11.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain==0.0.284) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.284)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting altair<5,>=3.2.0 (from streamlit==1.22.0)\n",
      "  Using cached altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: blinker>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (1.9.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (5.5.2)\n",
      "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (8.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (8.6.1)\n",
      "Requirement already satisfied: packaging>=14.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (2.2.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (11.1.0)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (20.0.0)\n",
      "Collecting pympler>=0.9 (from streamlit==1.22.0)\n",
      "  Using cached Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (2.9.0.post0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (14.0.0)\n",
      "Requirement already satisfied: toml in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (4.13.0)\n",
      "Collecting tzlocal>=1.1 (from streamlit==1.22.0)\n",
      "  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting validators>=0.2 (from streamlit==1.22.0)\n",
      "  Using cached validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (3.1.44)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (0.9.1)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from streamlit==1.22.0) (6.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from tiktoken==0.4.0) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284) (1.18.3)\n",
      "Collecting entrypoints (from altair<5,>=3.2.0->streamlit==1.22.0)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from altair<5,>=3.2.0->streamlit==1.22.0) (4.23.0)\n",
      "Collecting toolz (from altair<5,>=3.2.0->streamlit==1.22.0)\n",
      "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284) (3.26.1)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284)\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284) (0.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3,>=0.25->streamlit==1.22.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3,>=0.25->streamlit==1.22.0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1->langchain==0.0.284) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1->langchain==0.0.284) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1->langchain==0.0.284) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.0.284) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.0.284) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.0.284) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests<3,>=2->langchain==0.0.284) (2025.1.31)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-experimental) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-experimental) (0.3.72)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.0)\n",
      "  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.0.284)\n",
      "  Using cached SQLAlchemy-2.0.35-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.16 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.38 (from langchain-experimental)\n",
      "  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.16 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.10 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.0.63-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.0.62-py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached langchain_experimental-0.0.61-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.5 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.0.60-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langchain-community<0.3,>=0.2 (from langchain-experimental)\n",
      "  Using cached langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
      "  Using cached langchain_community-0.2.2-py3-none-any.whl.metadata (8.9 kB)\n",
      "  Using cached langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "  Using cached langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.0.59-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_experimental-0.0.57-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.56-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.55-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.54-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.53-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.52-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Using cached langchain_experimental-0.0.51-py3-none-any.whl.metadata (2.1 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_experimental-0.0.50-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_experimental-0.0.49-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_experimental-0.0.48-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_experimental-0.0.47-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_experimental-0.0.46-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_experimental-0.0.45-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_experimental-0.0.44-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.43-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.42-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.41-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.40-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.39-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.38-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.37-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.36-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.35-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.34-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.33-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.32-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.31-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.30-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.29-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.28-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.27-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached langchain_experimental-0.0.25-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (4.0.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (1.3.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gitpython!=3.1.19->streamlit==1.22.0) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.22.0) (5.0.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib-metadata>=1.4->streamlit==1.22.0) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0) (0.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Using cached googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "  Using cached googleapis_common_protos-1.69.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Using cached googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Using cached googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: pip is still looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached googleapis_common_protos-1.64.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Using cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting importlib-metadata>=1.4 (from streamlit==1.22.0)\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.53b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.53b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.53b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (75.8.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->altair<5,>=3.2.0->streamlit==1.22.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=10.11.0->streamlit==1.22.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=10.11.0->streamlit==1.22.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.22.0) (0.1.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached langchain-0.0.284-py3-none-any.whl (1.7 MB)\n",
      "Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Using cached streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
      "Using cached protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Using cached dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
      "Using cached langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached numexpr-2.11.0-cp313-cp313-macosx_11_0_arm64.whl (136 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_experimental-0.0.25-py3-none-any.whl (118 kB)\n",
      "Using cached mysql_connector_python-9.4.0-cp313-cp313-macosx_14_0_arm64.whl (17.5 MB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Using cached googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached Pympler-1.1-py3-none-any.whl (165 kB)\n",
      "Using cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Using cached validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: tiktoken, faiss-cpu\n",
      "  Building wheel for tiktoken (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tiktoken \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[49 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/_h/4hqg4gpj0yb_lqxf92_2c4y40000gn/T/pip-build-env-o896omsa/overlay/lib/python3.13/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   corresp(dist, value, root_dir)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/registry.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/core.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/model.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/load.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/tiktoken_ext\n",
      "  \u001b[31m   \u001b[0m copying tiktoken_ext/openai_public.py -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken_ext\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing tiktoken.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to tiktoken.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to tiktoken.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to tiktoken.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'tiktoken.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching 'Makefile'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'tiktoken.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/py.typed -> build/lib.macosx-10.13-universal2-cpython-313/tiktoken\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tiktoken\u001b[0m\u001b[31m\n",
      "\u001b[?25h  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[21 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/_h/4hqg4gpj0yb_lqxf92_2c4y40000gn/T/pip-build-env-xa946euy/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: MIT License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'faiss._swigfaiss' extension\n",
      "  \u001b[31m   \u001b[0m swigging faiss/faiss/python/swigfaiss.i to faiss/faiss/python/swigfaiss_wrap.cpp\n",
      "  \u001b[31m   \u001b[0m swig -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -module swigfaiss -o faiss/faiss/python/swigfaiss_wrap.cpp faiss/faiss/python/swigfaiss.i\n",
      "  \u001b[31m   \u001b[0m error: command 'swig' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build tiktoken faiss-cpu\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
      "\u001b[31m╰─>\u001b[0m tiktoken, faiss-cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==0.0.284 python-dotenv==1.0.0 streamlit==1.22.0 tiktoken==0.4.0 faiss-cpu==1.7.4 protobuf~=3.19.0 langchain-experimental mysql-connector-python pymysql sentence-transformers chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc152b3-2e9b-40e4-b45b-3a5b38ff50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"Question\", \"SQLQuery\", \"SQLResult\",\"Answer\",],\n",
    "    template=\"\\nQuestion: {Question}\\nSQLQuery: {SQLQuery}\\nSQLResult: {SQLResult}\\nAnswer: {Answer}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87bfe7b6-6e72-43b6-91f5-a9823177a4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/fy2v5h6s71v2mqh80d35xgjr0000gn/T/ipykernel_14717/210176126.py:27: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  q1 = db_chain(\"How many users are there in the database?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many users are there in the database?\n",
      "\u001b[32;1m\u001b[1;3mSELECT count(customerNumber) FROM customers\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(9,)]\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSELECT count(*) FROM customers\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'How many users are there in the database?', 'result': 'SELECT count(*) FROM customers', 'intermediate_steps': [{'input': 'How many users are there in the database?\\nSQLQuery:', 'top_k': '5', 'dialect': 'mysql', 'table_info': '\\nCREATE TABLE customers (\\n\\t`customerNumber` INTEGER NOT NULL, \\n\\t`customerName` VARCHAR(100), \\n\\t`contactLastName` VARCHAR(50), \\n\\t`contactFirstName` VARCHAR(50), \\n\\tphone VARCHAR(50), \\n\\t`addressLine1` VARCHAR(100), \\n\\tcity VARCHAR(50), \\n\\tcountry VARCHAR(50), \\n\\t`creditLimit` DECIMAL(10, 2), \\n\\tPRIMARY KEY (`customerNumber`)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from customers table:\\ncustomerNumber\\tcustomerName\\tcontactLastName\\tcontactFirstName\\tphone\\taddressLine1\\tcity\\tcountry\\tcreditLimit\\n101\\tAtelier graphique\\tSchmitt\\tCarine\\t40.32.2555\\t54, rue Royale\\tNantes\\tFrance\\t21000.00\\n102\\tSignal Gift Stores\\tKing\\tJean\\t7025551838\\t8489 Strong St.\\tLas Vegas\\tUSA\\t71800.00\\n103\\tAustralian Collectors\\tFerguson\\tPeter\\t03 9520 4555\\t636 St Kilda Road\\tMelbourne\\tAustralia\\t117300.00\\n*/\\n\\n\\nCREATE TABLE orders (\\n\\t`orderNumber` INTEGER NOT NULL, \\n\\t`orderDate` DATE, \\n\\tstatus VARCHAR(20), \\n\\t`customerNumber` INTEGER, \\n\\tPRIMARY KEY (`orderNumber`), \\n\\tCONSTRAINT orders_ibfk_1 FOREIGN KEY(`customerNumber`) REFERENCES customers (`customerNumber`)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from orders table:\\norderNumber\\torderDate\\tstatus\\tcustomerNumber\\n1001\\t2024-06-15\\tShipped\\t101\\n1002\\t2024-06-20\\tOn Hold\\t102\\n1003\\t2024-07-01\\tCancelled\\t103\\n*/\\n\\n\\nCREATE TABLE sample_adobe_feature_work_log (\\n\\tfeatureid VARCHAR(255), \\n\\tfeaturename VARCHAR(255), \\n\\tfeaturedescription VARCHAR(255), \\n\\tteam VARCHAR(255), \\n\\tissueid VARCHAR(255), \\n\\tstatus VARCHAR(255), \\n\\tchangedat DATETIME, \\n\\tassignedto VARCHAR(255), \\n\\tpriority VARCHAR(255)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from sample_adobe_feature_work_log table:\\nfeatureid\\tfeaturename\\tfeaturedescription\\tteam\\tissueid\\tstatus\\tchangedat\\tassignedto\\tpriority\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_01\\tLogged\\t2024-03-01 00:00:00\\temma_rojas\\tP4\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_02\\tLogged\\t2024-03-02 00:00:00\\tnoah_singh\\tP4\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_01\\tDeployed\\t2024-03-03 00:00:00\\temma_rojas\\tP4\\n*/\\n\\n\\nCREATE TABLE sample_with_anomalies (\\n\\tid FLOAT, \\n\\tname VARCHAR(255), \\n\\tage FLOAT, \\n\\temail VARCHAR(255), \\n\\tjoindate VARCHAR(255), \\n\\tsalary FLOAT\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from sample_with_anomalies table:\\nid\\tname\\tage\\temail\\tjoindate\\tsalary\\n1.0\\tAlice\\t25.0\\talice@example.com\\t2022-01-15\\t50000.0\\n2.0\\tBob\\t-30.0\\tbob[at]example.com\\t2022-02-30\\tNone\\nNone\\tCharlie\\t22.0\\tnan\\tNot a date\\t45000.0\\n*/', 'stop': ['\\nSQLResult:']}, 'SELECT count(customerNumber) FROM customers', {'sql_cmd': 'SELECT count(customerNumber) FROM customers'}, '[(9,)]', {'input': 'How many users are there in the database?\\nSQLQuery:SELECT count(customerNumber) FROM customers\\nSQLResult: [(9,)]\\nAnswer:', 'top_k': '5', 'dialect': 'mysql', 'table_info': '\\nCREATE TABLE customers (\\n\\t`customerNumber` INTEGER NOT NULL, \\n\\t`customerName` VARCHAR(100), \\n\\t`contactLastName` VARCHAR(50), \\n\\t`contactFirstName` VARCHAR(50), \\n\\tphone VARCHAR(50), \\n\\t`addressLine1` VARCHAR(100), \\n\\tcity VARCHAR(50), \\n\\tcountry VARCHAR(50), \\n\\t`creditLimit` DECIMAL(10, 2), \\n\\tPRIMARY KEY (`customerNumber`)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from customers table:\\ncustomerNumber\\tcustomerName\\tcontactLastName\\tcontactFirstName\\tphone\\taddressLine1\\tcity\\tcountry\\tcreditLimit\\n101\\tAtelier graphique\\tSchmitt\\tCarine\\t40.32.2555\\t54, rue Royale\\tNantes\\tFrance\\t21000.00\\n102\\tSignal Gift Stores\\tKing\\tJean\\t7025551838\\t8489 Strong St.\\tLas Vegas\\tUSA\\t71800.00\\n103\\tAustralian Collectors\\tFerguson\\tPeter\\t03 9520 4555\\t636 St Kilda Road\\tMelbourne\\tAustralia\\t117300.00\\n*/\\n\\n\\nCREATE TABLE orders (\\n\\t`orderNumber` INTEGER NOT NULL, \\n\\t`orderDate` DATE, \\n\\tstatus VARCHAR(20), \\n\\t`customerNumber` INTEGER, \\n\\tPRIMARY KEY (`orderNumber`), \\n\\tCONSTRAINT orders_ibfk_1 FOREIGN KEY(`customerNumber`) REFERENCES customers (`customerNumber`)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from orders table:\\norderNumber\\torderDate\\tstatus\\tcustomerNumber\\n1001\\t2024-06-15\\tShipped\\t101\\n1002\\t2024-06-20\\tOn Hold\\t102\\n1003\\t2024-07-01\\tCancelled\\t103\\n*/\\n\\n\\nCREATE TABLE sample_adobe_feature_work_log (\\n\\tfeatureid VARCHAR(255), \\n\\tfeaturename VARCHAR(255), \\n\\tfeaturedescription VARCHAR(255), \\n\\tteam VARCHAR(255), \\n\\tissueid VARCHAR(255), \\n\\tstatus VARCHAR(255), \\n\\tchangedat DATETIME, \\n\\tassignedto VARCHAR(255), \\n\\tpriority VARCHAR(255)\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from sample_adobe_feature_work_log table:\\nfeatureid\\tfeaturename\\tfeaturedescription\\tteam\\tissueid\\tstatus\\tchangedat\\tassignedto\\tpriority\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_01\\tLogged\\t2024-03-01 00:00:00\\temma_rojas\\tP4\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_02\\tLogged\\t2024-03-02 00:00:00\\tnoah_singh\\tP4\\nADOBE_FTR_02\\tPhotoshop Neural Filters\\tPortrait retouch and style transfer tools\\tExperience Design\\tADOBE_FTR_02_ISSUE_01\\tDeployed\\t2024-03-03 00:00:00\\temma_rojas\\tP4\\n*/\\n\\n\\nCREATE TABLE sample_with_anomalies (\\n\\tid FLOAT, \\n\\tname VARCHAR(255), \\n\\tage FLOAT, \\n\\temail VARCHAR(255), \\n\\tjoindate VARCHAR(255), \\n\\tsalary FLOAT\\n)COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\\n\\n/*\\n3 rows from sample_with_anomalies table:\\nid\\tname\\tage\\temail\\tjoindate\\tsalary\\n1.0\\tAlice\\t25.0\\talice@example.com\\t2022-01-15\\t50000.0\\n2.0\\tBob\\t-30.0\\tbob[at]example.com\\t2022-02-30\\tNone\\nNone\\tCharlie\\t22.0\\tnan\\tNot a date\\t45000.0\\n*/', 'stop': ['\\nSQLResult:']}, 'SELECT count(*) FROM customers']}\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains.sql_database.prompt import PROMPT\n",
    "\n",
    "# Create custom prompt that specifically asks for clean SQL\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\"],\n",
    "    template=\"\"\"Given an input question, create a syntactically correct MySQL query to run.\n",
    "\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Important: Return ONLY the SQL query without any markdown formatting, explanations, or code blocks. Do not use ```sql``` formatting.\n",
    "\n",
    "SQL Query:\"\"\"\n",
    ")\n",
    "\n",
    "# Create chain with custom prompt\n",
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm=llm, \n",
    "    db=db, \n",
    "    prompt=custom_prompt,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "q1 = db_chain(\"How many users are there in the database?\")\n",
    "print(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848beaf9-1266-4151-9efb-3210a9d1e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Show me all sales where customers bought mobiles with a discount applied.\n",
      "\u001b[32;1m\u001b[1;3mSELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts);\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(1, 1, 1, 1, 1, 58500, datetime.date(2025, 7, 12)), (2, 3, 2, 2, 2, 57000, datetime.date(2025, 7, 15)), (3, 5, 3, 1, 1, 80750, datetime.date(2025, 7, 16)), (4, 6, 4, 3, 1, 29760, datetime.date(2025, 7, 20)), (5, 7, 5, 5, 2, 27000, datetime.date(2025, 7, 22)), (6, 8, 6, 2, 1, 87120, datetime.date(2025, 7, 26)), (7, 9, 7, 1, 1, 63920, datetime.date(2025, 7, 28)), (8, 10, 8, 4, 1, 82450, datetime.date(2025, 7, 29))]\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts)\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Show me all sales where customers bought mobiles with a discount applied.', 'result': 'SELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts)', 'intermediate_steps': [{'input': 'Show me all sales where customers bought mobiles with a discount applied.\\nSQLQuery:', 'top_k': '5', 'dialect': 'mysql', 'table_info': \"\\nCREATE TABLE customers (\\n\\tcustomer_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tname VARCHAR(100) NOT NULL, \\n\\temail VARCHAR(100), \\n\\tphone VARCHAR(15), \\n\\tcity VARCHAR(50), \\n\\tPRIMARY KEY (customer_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from customers table:\\ncustomer_id\\tname\\temail\\tphone\\tcity\\n1\\tRahul Sharma\\trahul@example.com\\t9876543210\\tDelhi\\n2\\tPriya Mehta\\tpriya@example.com\\t9765432198\\tMumbai\\n3\\tAman Verma\\taman@example.com\\t9654321987\\tBangalore\\n*/\\n\\n\\nCREATE TABLE discounts (\\n\\tdiscount_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmobile_id INTEGER, \\n\\tdiscount_percent INTEGER, \\n\\tstart_date DATE, \\n\\tend_date DATE, \\n\\tPRIMARY KEY (discount_id), \\n\\tCONSTRAINT discounts_ibfk_1 FOREIGN KEY(mobile_id) REFERENCES mobiles (mobile_id), \\n\\tCONSTRAINT discounts_chk_1 CHECK ((`discount_percent` between 0 and 50))\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from discounts table:\\ndiscount_id\\tmobile_id\\tdiscount_percent\\tstart_date\\tend_date\\n1\\t1\\t10\\t2025-07-01\\t2025-07-15\\n2\\t3\\t5\\t2025-07-10\\t2025-07-20\\n3\\t5\\t15\\t2025-07-05\\t2025-07-25\\n*/\\n\\n\\nCREATE TABLE mobiles (\\n\\tmobile_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmodel ENUM('Galaxy S21','Galaxy S22','Galaxy A52','Galaxy M12','Galaxy Z Flip') NOT NULL, \\n\\tcolor ENUM('Phantom Black','Phantom White','Lavender','Green','Blue') NOT NULL, \\n\\tstorage ENUM('64GB','128GB','256GB','512GB') NOT NULL, \\n\\tram ENUM('4GB','6GB','8GB','12GB') NOT NULL, \\n\\tprice INTEGER, \\n\\tstock_quantity INTEGER NOT NULL, \\n\\tPRIMARY KEY (mobile_id), \\n\\tCONSTRAINT mobiles_chk_1 CHECK ((`price` between 10000 and 150000))\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from mobiles table:\\nmobile_id\\tmodel\\tcolor\\tstorage\\tram\\tprice\\tstock_quantity\\n1\\tGalaxy S21\\tPhantom Black\\t128GB\\t8GB\\t65000\\t20\\n2\\tGalaxy S22\\tPhantom White\\t256GB\\t12GB\\t85000\\t15\\n3\\tGalaxy A52\\tBlue\\t128GB\\t6GB\\t30000\\t30\\n*/\\n\\n\\nCREATE TABLE sales (\\n\\tsale_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmobile_id INTEGER, \\n\\tcustomer_id INTEGER, \\n\\tstaff_id INTEGER, \\n\\tquantity INTEGER NOT NULL, \\n\\ttotal_amount INTEGER, \\n\\tsale_date DATE, \\n\\tPRIMARY KEY (sale_id), \\n\\tCONSTRAINT sales_ibfk_1 FOREIGN KEY(mobile_id) REFERENCES mobiles (mobile_id), \\n\\tCONSTRAINT sales_ibfk_2 FOREIGN KEY(customer_id) REFERENCES customers (customer_id), \\n\\tCONSTRAINT sales_ibfk_3 FOREIGN KEY(staff_id) REFERENCES staff (staff_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from sales table:\\nsale_id\\tmobile_id\\tcustomer_id\\tstaff_id\\tquantity\\ttotal_amount\\tsale_date\\n1\\t1\\t1\\t1\\t1\\t58500\\t2025-07-12\\n2\\t3\\t2\\t2\\t2\\t57000\\t2025-07-15\\n3\\t5\\t3\\t1\\t1\\t80750\\t2025-07-16\\n*/\\n\\n\\nCREATE TABLE staff (\\n\\tstaff_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tname VARCHAR(100), \\n\\tposition VARCHAR(50), \\n\\tPRIMARY KEY (staff_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from staff table:\\nstaff_id\\tname\\tposition\\n1\\tAnjali Singh\\tSales Executive\\n2\\tRavi Kumar\\tStore Manager\\n3\\tSuman Tiwari\\tAssistant Sales\\n*/\", 'stop': ['\\nSQLResult:']}, 'SELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts);', {'sql_cmd': 'SELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts);'}, '[(1, 1, 1, 1, 1, 58500, datetime.date(2025, 7, 12)), (2, 3, 2, 2, 2, 57000, datetime.date(2025, 7, 15)), (3, 5, 3, 1, 1, 80750, datetime.date(2025, 7, 16)), (4, 6, 4, 3, 1, 29760, datetime.date(2025, 7, 20)), (5, 7, 5, 5, 2, 27000, datetime.date(2025, 7, 22)), (6, 8, 6, 2, 1, 87120, datetime.date(2025, 7, 26)), (7, 9, 7, 1, 1, 63920, datetime.date(2025, 7, 28)), (8, 10, 8, 4, 1, 82450, datetime.date(2025, 7, 29))]', {'input': 'Show me all sales where customers bought mobiles with a discount applied.\\nSQLQuery:SELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts);\\nSQLResult: [(1, 1, 1, 1, 1, 58500, datetime.date(2025, 7, 12)), (2, 3, 2, 2, 2, 57000, datetime.date(2025, 7, 15)), (3, 5, 3, 1, 1, 80750, datetime.date(2025, 7, 16)), (4, 6, 4, 3, 1, 29760, datetime.date(2025, 7, 20)), (5, 7, 5, 5, 2, 27000, datetime.date(2025, 7, 22)), (6, 8, 6, 2, 1, 87120, datetime.date(2025, 7, 26)), (7, 9, 7, 1, 1, 63920, datetime.date(2025, 7, 28)), (8, 10, 8, 4, 1, 82450, datetime.date(2025, 7, 29))]\\nAnswer:', 'top_k': '5', 'dialect': 'mysql', 'table_info': \"\\nCREATE TABLE customers (\\n\\tcustomer_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tname VARCHAR(100) NOT NULL, \\n\\temail VARCHAR(100), \\n\\tphone VARCHAR(15), \\n\\tcity VARCHAR(50), \\n\\tPRIMARY KEY (customer_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from customers table:\\ncustomer_id\\tname\\temail\\tphone\\tcity\\n1\\tRahul Sharma\\trahul@example.com\\t9876543210\\tDelhi\\n2\\tPriya Mehta\\tpriya@example.com\\t9765432198\\tMumbai\\n3\\tAman Verma\\taman@example.com\\t9654321987\\tBangalore\\n*/\\n\\n\\nCREATE TABLE discounts (\\n\\tdiscount_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmobile_id INTEGER, \\n\\tdiscount_percent INTEGER, \\n\\tstart_date DATE, \\n\\tend_date DATE, \\n\\tPRIMARY KEY (discount_id), \\n\\tCONSTRAINT discounts_ibfk_1 FOREIGN KEY(mobile_id) REFERENCES mobiles (mobile_id), \\n\\tCONSTRAINT discounts_chk_1 CHECK ((`discount_percent` between 0 and 50))\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from discounts table:\\ndiscount_id\\tmobile_id\\tdiscount_percent\\tstart_date\\tend_date\\n1\\t1\\t10\\t2025-07-01\\t2025-07-15\\n2\\t3\\t5\\t2025-07-10\\t2025-07-20\\n3\\t5\\t15\\t2025-07-05\\t2025-07-25\\n*/\\n\\n\\nCREATE TABLE mobiles (\\n\\tmobile_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmodel ENUM('Galaxy S21','Galaxy S22','Galaxy A52','Galaxy M12','Galaxy Z Flip') NOT NULL, \\n\\tcolor ENUM('Phantom Black','Phantom White','Lavender','Green','Blue') NOT NULL, \\n\\tstorage ENUM('64GB','128GB','256GB','512GB') NOT NULL, \\n\\tram ENUM('4GB','6GB','8GB','12GB') NOT NULL, \\n\\tprice INTEGER, \\n\\tstock_quantity INTEGER NOT NULL, \\n\\tPRIMARY KEY (mobile_id), \\n\\tCONSTRAINT mobiles_chk_1 CHECK ((`price` between 10000 and 150000))\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from mobiles table:\\nmobile_id\\tmodel\\tcolor\\tstorage\\tram\\tprice\\tstock_quantity\\n1\\tGalaxy S21\\tPhantom Black\\t128GB\\t8GB\\t65000\\t20\\n2\\tGalaxy S22\\tPhantom White\\t256GB\\t12GB\\t85000\\t15\\n3\\tGalaxy A52\\tBlue\\t128GB\\t6GB\\t30000\\t30\\n*/\\n\\n\\nCREATE TABLE sales (\\n\\tsale_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmobile_id INTEGER, \\n\\tcustomer_id INTEGER, \\n\\tstaff_id INTEGER, \\n\\tquantity INTEGER NOT NULL, \\n\\ttotal_amount INTEGER, \\n\\tsale_date DATE, \\n\\tPRIMARY KEY (sale_id), \\n\\tCONSTRAINT sales_ibfk_1 FOREIGN KEY(mobile_id) REFERENCES mobiles (mobile_id), \\n\\tCONSTRAINT sales_ibfk_2 FOREIGN KEY(customer_id) REFERENCES customers (customer_id), \\n\\tCONSTRAINT sales_ibfk_3 FOREIGN KEY(staff_id) REFERENCES staff (staff_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from sales table:\\nsale_id\\tmobile_id\\tcustomer_id\\tstaff_id\\tquantity\\ttotal_amount\\tsale_date\\n1\\t1\\t1\\t1\\t1\\t58500\\t2025-07-12\\n2\\t3\\t2\\t2\\t2\\t57000\\t2025-07-15\\n3\\t5\\t3\\t1\\t1\\t80750\\t2025-07-16\\n*/\\n\\n\\nCREATE TABLE staff (\\n\\tstaff_id INTEGER NOT NULL AUTO_INCREMENT, \\n\\tname VARCHAR(100), \\n\\tposition VARCHAR(50), \\n\\tPRIMARY KEY (staff_id)\\n)ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\\n\\n/*\\n3 rows from staff table:\\nstaff_id\\tname\\tposition\\n1\\tAnjali Singh\\tSales Executive\\n2\\tRavi Kumar\\tStore Manager\\n3\\tSuman Tiwari\\tAssistant Sales\\n*/\", 'stop': ['\\nSQLResult:']}, 'SELECT * FROM sales WHERE mobile_id IN (SELECT mobile_id FROM discounts)']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q2 = db_chain(\"Show me all sales where customers bought mobiles with a discount applied.\")\n",
    "print(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac50452-aff6-4ebf-b107-a7c37f63115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Anjali Singh', Decimal('203170'))]\n"
     ]
    }
   ],
   "source": [
    "result = db.run(\"\"\"\n",
    "SELECT s.name AS staff_name, SUM(sa.total_amount) AS total_revenue\n",
    "FROM sales sa\n",
    "JOIN staff s ON sa.staff_id = s.staff_id\n",
    "GROUP BY s.name\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 1;\n",
    "\"\"\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d4b5782-122f-473c-a1d4-42159b8d0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Priya Mehta', 'Mumbai', Decimal('2'))]\n"
     ]
    }
   ],
   "source": [
    "result1 = db.run(\"\"\"\n",
    "SELECT c.name, c.city, SUM(sa.quantity) AS total_mobiles_bought\n",
    "FROM sales sa\n",
    "JOIN customers c ON sa.customer_id = c.customer_id\n",
    "WHERE c.city = 'Mumbai'\n",
    "GROUP BY c.customer_id, c.name, c.city\n",
    "HAVING total_mobiles_bought > 1;\n",
    "\"\"\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96a36927-1b66-493e-b171-68f622599030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy S21', Decimal('2'), Decimal('44130.00000000')), ('Galaxy A52', Decimal('3'), Decimal('57810.00000000')), ('Galaxy Z Flip', Decimal('2'), Decimal('81600.00000000')), ('Galaxy S22', Decimal('2'), Decimal('13500.00000000')), ('Galaxy M12', Decimal('1'), Decimal('63920.00000000'))]\n"
     ]
    }
   ],
   "source": [
    "result2 = db.run(\"\"\"\n",
    "SELECT m.model, SUM(sa.quantity) AS total_sold, AVG(sa.total_amount / sa.quantity) AS avg_price_per_unit\n",
    "FROM sales sa\n",
    "JOIN mobiles m ON sa.mobile_id = m.mobile_id\n",
    "GROUP BY m.model;\n",
    "\n",
    "\"\"\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457b31c5-8996-4aab-8f18-9dc2ae6bf515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy A52', 87120, 'Meena Iyer', datetime.date(2025, 7, 26))]\n"
     ]
    }
   ],
   "source": [
    "result3 = db.run(\"\"\"\n",
    "SELECT m.model, sa.total_amount, c.name AS customer_name, sa.sale_date\n",
    "FROM sales sa\n",
    "JOIN mobiles m ON sa.mobile_id = m.mobile_id\n",
    "JOIN customers c ON sa.customer_id = c.customer_id\n",
    "ORDER BY sa.total_amount DESC\n",
    "LIMIT 1;\n",
    "\n",
    "\"\"\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664f564b-d68c-4691-9c4e-7b68328c81f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy S21', 10, datetime.date(2025, 7, 1), datetime.date(2025, 7, 15)), ('Galaxy A52', 5, datetime.date(2025, 7, 10), datetime.date(2025, 7, 20)), ('Galaxy Z Flip', 15, datetime.date(2025, 7, 5), datetime.date(2025, 7, 25))]\n"
     ]
    }
   ],
   "source": [
    "result4 = db.run(\"\"\"\n",
    "SELECT m.model, d.discount_percent, d.start_date, d.end_date\n",
    "FROM discounts d\n",
    "JOIN mobiles m ON d.mobile_id = m.mobile_id\n",
    "WHERE '2025-07-12' BETWEEN d.start_date AND d.end_date;\n",
    "\n",
    "\"\"\")\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02448d75-84c6-4874-aaf9-d5966e9455ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy Z Flip', Decimal('163200'))]\n"
     ]
    }
   ],
   "source": [
    "result5 = db.run(\"\"\"\n",
    "SELECT m.model, SUM(sa.total_amount) AS total_revenue\n",
    "FROM sales sa\n",
    "JOIN mobiles m ON sa.mobile_id = m.mobile_id\n",
    "GROUP BY m.model\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 1;\n",
    "\"\"\")\n",
    "print(result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7802f9d6-f23d-4b36-9452-00d6e067ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Chennai', Decimal('87120')), ('Kolkata', Decimal('82450')), ('Bangalore', Decimal('80750'))]\n"
     ]
    }
   ],
   "source": [
    "result6 = db.run(\"\"\"\n",
    "SELECT c.city, SUM(sa.total_amount) AS total_revenue\n",
    "FROM sales sa\n",
    "JOIN customers c ON sa.customer_id = c.customer_id\n",
    "GROUP BY c.city\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 3;\n",
    "\"\"\")\n",
    "print(result6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edc93c5e-2631-4bef-8b8a-874f98378def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result7 = db.run(\"\"\"\n",
    "SELECT model, color, storage, ram, stock_quantity\n",
    "FROM mobiles\n",
    "WHERE stock_quantity = 0;\n",
    "\"\"\")\n",
    "print(result7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1912350f-b31d-4978-8957-e58e724d4826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rahul Sharma', Decimal('58500')), ('Priya Mehta', Decimal('57000')), ('Aman Verma', Decimal('80750')), ('Sneha Reddy', Decimal('29760')), ('Karan Patel', Decimal('27000')), ('Meena Iyer', Decimal('87120')), ('Nikhil Rao', Decimal('63920')), ('Anita Joshi', Decimal('82450'))]\n"
     ]
    }
   ],
   "source": [
    "result8 = db.run(\"\"\"\n",
    "SELECT c.name, COALESCE(SUM(sa.total_amount), 0) AS total_spent\n",
    "FROM customers c\n",
    "LEFT JOIN sales sa ON c.customer_id = sa.customer_id\n",
    "GROUP BY c.customer_id, c.name;\n",
    "\n",
    "\"\"\")\n",
    "print(result8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "808c7410-b971-453f-b244-4dccdab4d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Anjali Singh', 3)]\n"
     ]
    }
   ],
   "source": [
    "result9 = db.run(\"\"\"\n",
    "SELECT s.name, COUNT(DISTINCT sa.mobile_id) AS different_models_sold\n",
    "FROM sales sa\n",
    "JOIN staff s ON sa.staff_id = s.staff_id\n",
    "GROUP BY s.staff_id, s.name\n",
    "ORDER BY different_models_sold DESC\n",
    "LIMIT 1;\n",
    "\n",
    "\"\"\")\n",
    "print(result9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d7de2f3-8ae8-41fe-be76-2f6bc58cc023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Anjali Singh', Decimal('1.0000')), ('Ravi Kumar', Decimal('1.5000')), ('Suman Tiwari', Decimal('1.0000')), ('Mohit Jain', Decimal('2.0000')), ('Deepika Nair', Decimal('1.0000'))]\n"
     ]
    }
   ],
   "source": [
    "result10 = db.run(\"\"\"\n",
    "SELECT s.name, AVG(sa.quantity) AS avg_quantity_per_sale\n",
    "FROM sales sa\n",
    "JOIN staff s ON sa.staff_id = s.staff_id\n",
    "GROUP BY s.name;\n",
    "\n",
    "\"\"\")\n",
    "print(result10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f2c0840-c375-4dd1-bbc1-d3daa26de47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Priya Mehta', Decimal('2'))]\n"
     ]
    }
   ],
   "source": [
    "result11 = db.run(\"\"\"\n",
    "SELECT c.name, SUM(sa.quantity) AS total_quantity\n",
    "FROM sales sa\n",
    "JOIN customers c ON sa.customer_id = c.customer_id\n",
    "GROUP BY c.customer_id, c.name\n",
    "ORDER BY total_quantity DESC\n",
    "LIMIT 1;\n",
    "\n",
    "\"\"\")\n",
    "print(result11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b63d414-f430-4da7-be58-f41da1d9cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy S21', Decimal('88260')), ('Galaxy A52', Decimal('144120')), ('Galaxy Z Flip', Decimal('163200')), ('Galaxy S22', Decimal('27000')), ('Galaxy M12', Decimal('63920'))]\n"
     ]
    }
   ],
   "source": [
    "result12 = db.run(\"\"\"\n",
    "SELECT m.model, SUM(sa.total_amount) AS revenue_during_discount\n",
    "FROM sales sa\n",
    "JOIN mobiles m ON sa.mobile_id = m.mobile_id\n",
    "JOIN discounts d ON sa.mobile_id = d.mobile_id\n",
    "WHERE sa.sale_date BETWEEN d.start_date AND d.end_date\n",
    "GROUP BY m.model;\n",
    "\"\"\")\n",
    "print(result12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a726f0fe-7673-4777-9f0f-613249a12082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy Z Flip', 15)]\n"
     ]
    }
   ],
   "source": [
    "result13 = db.run(\"\"\"\n",
    "SELECT m.model, d.discount_percent\n",
    "FROM discounts d\n",
    "JOIN mobiles m ON d.mobile_id = m.mobile_id\n",
    "WHERE '2025-07-15' BETWEEN d.start_date AND d.end_date\n",
    "  AND d.discount_percent > 10;\n",
    "\n",
    "\"\"\")\n",
    "print(result13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74af3ee8-bff8-4ac5-92c3-30ea825121de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galaxy S21', 2), ('Galaxy S22', 1), ('Galaxy A52', 2), ('Galaxy M12', 1), ('Galaxy Z Flip', 2)]\n"
     ]
    }
   ],
   "source": [
    "result14 = db.run(\"\"\"\n",
    "SELECT m.model, COUNT(DISTINCT sa.customer_id) AS unique_customers\n",
    "FROM sales sa\n",
    "JOIN mobiles m ON sa.mobile_id = m.mobile_id\n",
    "GROUP BY m.model;\n",
    "\"\"\")\n",
    "print(result14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc5f5932-cc73-4799-9c02-add86a6fff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shots = [\n",
    "    {'Question': \"Which staff member generated the highest total sales revenue, and how much was it?\",\n",
    "     'SQLQuery': \"SELECT s.name AS staff_name, SUM(sa.total_amount) AS total_revenue FROM sales sa JOIN staff s ON sa.staff_id = s.staff_id GROUP BY s.name ORDER BY total_revenue DESC LIMIT 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result},\n",
    "    {'Question': \"List all customers from Mumbai who purchased more than one mobile in total.\",\n",
    "     'SQLQuery': \"SELECT c.name, c.city, SUM(sa.quantity) AS total_mobiles_bought FROM sales sa JOIN customers c ON sa.customer_id = c.customer_id WHERE c.city = 'Mumbai' GROUP BY c.customer_id, c.name, c.city HAVING total_mobiles_bought > 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result1},\n",
    "    {'Question': \"For each mobile model, show the total quantity sold and the average sale price.\",\n",
    "     'SQLQuery': \"SELECT m.model, SUM(sa.quantity) AS total_sold, AVG(sa.total_amount / sa.quantity) AS avg_price_per_unit FROM sales sa JOIN mobiles m ON sa.mobile_id = m.mobile_id GROUP BY m.model;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result2},\n",
    "    {'Question': \"Find the most expensive mobile ever sold (after discounts) and who bought it.\",\n",
    "     'SQLQuery': \"SELECT m.model, sa.total_amount, c.name AS customer_name, sa.sale_date FROM sales sa JOIN mobiles m ON sa.mobile_id = m.mobile_id JOIN customers c ON sa.customer_id = c.customer_id ORDER BY sa.total_amount DESC LIMIT 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result3},\n",
    "    {'Question': \"Show all ongoing discounts as of '2025-07-12' and the models they apply to.\",\n",
    "     'SQLQuery': \"SELECT m.model, d.discount_percent, d.start_date, d.end_date FROM discounts d JOIN mobiles m ON d.mobile_id = m.mobile_id WHERE '2025-07-12' BETWEEN d.start_date AND d.end_date;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result4},\n",
    "    {'Question': \"Which mobile model has generated the highest revenue overall, and how much?\",\n",
    "     'SQLQuery': \"SELECT m.model, SUM(sa.total_amount) AS total_revenue FROM sales sa JOIN mobiles m ON sa.mobile_id = m.mobile_id GROUP BY m.model ORDER BY total_revenue DESC LIMIT 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result5},\n",
    "    {'Question': \"Show the top 3 cities by total sales revenue.\",\n",
    "     'SQLQuery': \"SELECT c.city, SUM(sa.total_amount) AS total_revenue FROM sales sa JOIN customers c ON sa.customer_id = c.customer_id GROUP BY c.city ORDER BY total_revenue DESC LIMIT 3;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result6},\n",
    "    {'Question': \"Find all mobiles that are completely out of stock.\",\n",
    "     'SQLQuery': \"SELECT model, color, storage, ram, stock_quantity FROM mobiles WHERE stock_quantity = 0;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result7},\n",
    "    {'Question': \"List all customers and the total amount they have spent, even if they bought nothing.\",\n",
    "     'SQLQuery': \"SELECT c.name, COALESCE(SUM(sa.total_amount), 0) AS total_spent FROM customers c LEFT JOIN sales sa ON c.customer_id = sa.customer_id GROUP BY c.customer_id, c.name;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result8},\n",
    "    {'Question': \"Which staff member sold the highest number of different mobile models?\",\n",
    "     'SQLQuery': \"SELECT s.name, COUNT(DISTINCT sa.mobile_id) AS different_models_sold FROM sales sa JOIN staff s ON sa.staff_id = s.staff_id GROUP BY s.staff_id, s.name ORDER BY different_models_sold DESC LIMIT 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result9},\n",
    "    {'Question': \"Show the average quantity sold per transaction for each staff member.\",\n",
    "     'SQLQuery': \"SELECT s.name, AVG(sa.quantity) AS avg_quantity_per_sale FROM sales sa JOIN staff s ON sa.staff_id = s.staff_id GROUP BY s.name;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result10},\n",
    "    {'Question': \"Find the customer who has purchased the highest total quantity of mobiles.\",\n",
    "     'SQLQuery': \"SELECT c.name, SUM(sa.quantity) AS total_quantity FROM sales sa JOIN customers c ON sa.customer_id = c.customer_id GROUP BY c.customer_id, c.name ORDER BY total_quantity DESC LIMIT 1;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result11},\n",
    "    {'Question': \"Show the total revenue generated from each mobile model during discount periods only.\",\n",
    "     'SQLQuery': \"SELECT m.model, SUM(sa.total_amount) AS revenue_during_discount FROM sales sa JOIN mobiles m ON sa.mobile_id = m.mobile_id JOIN discounts d ON sa.mobile_id = d.mobile_id WHERE sa.sale_date BETWEEN d.start_date AND d.end_date GROUP BY m.model;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer':result12},\n",
    "    {'Question': \"Find all mobiles with a discount greater than 10% currently active on '2025-07-15'.\",\n",
    "     'SQLQuery': \"SELECT m.model, d.discount_percent FROM discounts d JOIN mobiles m ON d.mobile_id = m.mobile_id WHERE '2025-07-15' BETWEEN d.start_date AND d.end_date AND d.discount_percent > 10;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result13},\n",
    "    {'Question': \"Show each mobile model and the number of unique customers who purchased it.\",\n",
    "     'SQLQuery': \"SELECT m.model, COUNT(DISTINCT sa.customer_id) AS unique_customers FROM sales sa JOIN mobiles m ON sa.mobile_id = m.mobile_id GROUP BY m.model;\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': result14}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5afceb59-1738-4eee-9e4e-6270dc17b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create custom SQL chain class that removes markdown\n",
    "import re\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "class CleaningSQLDatabaseChain(SQLDatabaseChain):\n",
    "    def clean_sql_query(self, sql_text):\n",
    "        \"\"\"Remove markdown formatting from SQL\"\"\"\n",
    "        # Remove ```sql and ``` markers\n",
    "        sql_text = re.sub(r'```sql\\s*', '', sql_text, flags=re.IGNORECASE)\n",
    "        sql_text = re.sub(r'```', '', sql_text)\n",
    "        sql_text = sql_text.strip()\n",
    "        \n",
    "        # Ensure semicolon at end\n",
    "        if sql_text and not sql_text.endswith(';'):\n",
    "            sql_text += ';'\n",
    "        \n",
    "        return sql_text\n",
    "    \n",
    "    def _call(self, inputs, run_manager=None):\n",
    "        try:\n",
    "            # Generate SQL query using LLM\n",
    "            llm_response = self.llm_chain.predict(\n",
    "                input=inputs[self.input_key],\n",
    "                table_info=self.database.get_table_info(),\n",
    "                top_k=str(getattr(self, 'top_k', 5))\n",
    "            )\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Raw LLM Response: {llm_response}\")\n",
    "            \n",
    "            # Extract SQL from response\n",
    "            sql_query = \"\"\n",
    "            lines = llm_response.split('\\n')\n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                if 'SQLQuery:' in line:\n",
    "                    sql_start = line.split('SQLQuery:')[1].strip()\n",
    "                    if sql_start:\n",
    "                        sql_query = sql_start\n",
    "                    # Continue reading until SQLResult or Answer\n",
    "                    for j in range(i + 1, len(lines)):\n",
    "                        if lines[j].strip().startswith(('SQLResult:', 'Answer:')):\n",
    "                            break\n",
    "                        if lines[j].strip():\n",
    "                            sql_query += ' ' + lines[j].strip()\n",
    "                    break\n",
    "            \n",
    "            # If no SQLQuery found, try pattern matching\n",
    "            if not sql_query:\n",
    "                sql_pattern = r'(SELECT|INSERT|UPDATE|DELETE).*?(?=\\n\\n|\\nSQLResult|\\nAnswer|$)'\n",
    "                match = re.search(sql_pattern, llm_response, re.IGNORECASE | re.DOTALL)\n",
    "                if match:\n",
    "                    sql_query = match.group(0)\n",
    "            \n",
    "            # Clean the SQL\n",
    "            cleaned_sql = self.clean_sql_query(sql_query)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Cleaned SQL: {cleaned_sql}\")\n",
    "            \n",
    "            # Execute SQL\n",
    "            result = self.database.run(cleaned_sql)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"SQL Result: {result}\")\n",
    "            \n",
    "            return {self.output_key: result}\n",
    "            \n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "            return {self.output_key: f\"Error executing query: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b84ee86-ce67-4cd4-a778-d06d1a196aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create custom prompt that explicitly avoids markdown\n",
    "custom_mysql_prompt = \"\"\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run.\n",
    "\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist.\n",
    "\n",
    "Use the following format exactly:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run (DO NOT use markdown formatting like ```sql```)\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d28ad7-779c-4a59-adc8-b7ad584a9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create embeddings (your existing code with small fix)\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Fix the vectorization to handle all data types\n",
    "to_vectorize = [\" \".join([str(v) for v in example.values()]) for example in few_shots]\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embedding=embeddings, metadatas=few_shots)\n",
    "\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d85a4ea-f207-46f3-9de0-b28b977f0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create templates\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"Question\", \"SQLQuery\", \"SQLResult\", \"Answer\"],\n",
    "    template=\"\\nQuestion: {Question}\\nSQLQuery: {SQLQuery}\\nSQLResult: {SQLResult}\\nAnswer: {Answer}\",\n",
    ")\n",
    "\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=custom_mysql_prompt,  # Use the custom prompt from Step 3\n",
    "    suffix=\"\",\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a23f602c-a992-4e4c-976b-13e60950c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CleaningSQLDatabaseChain chain...\u001b[0m\n",
      "Raw LLM Response: Question: Find the names of customers who bought a mobile during its discount period, along with the mobile model, discount percentage, and the name of the staff who handled the sale.\n",
      "SQLQuery: SELECT c.name, m.model, d.discount_percent, s.name AS staff_name FROM sales AS sa JOIN customers AS c ON sa.customer_id = c.customer_id JOIN mobiles AS m ON sa.mobile_id = m.mobile_id JOIN discounts AS d ON m.mobile_id = d.mobile_id JOIN staff AS s ON sa.staff_id = s.staff_id WHERE sa.sale_date BETWEEN d.start_date AND d.end_date;\n",
      "SQLResult: Result of the SQL query\n",
      "Answer: []\n",
      "Cleaned SQL: SELECT c.name, m.model, d.discount_percent, s.name AS staff_name FROM sales AS sa JOIN customers AS c ON sa.customer_id = c.customer_id JOIN mobiles AS m ON sa.mobile_id = m.mobile_id JOIN discounts AS d ON m.mobile_id = d.mobile_id JOIN staff AS s ON sa.staff_id = s.staff_id WHERE sa.sale_date BETWEEN d.start_date AND d.end_date;\n",
      "SQL Result: [('Rahul Sharma', 'Galaxy S21', 10, 'Anjali Singh'), ('Priya Mehta', 'Galaxy A52', 5, 'Ravi Kumar'), ('Aman Verma', 'Galaxy Z Flip', 15, 'Anjali Singh'), ('Sneha Reddy', 'Galaxy S21', 7, 'Suman Tiwari'), ('Karan Patel', 'Galaxy S22', 10, 'Mohit Jain'), ('Meena Iyer', 'Galaxy A52', 12, 'Ravi Kumar'), ('Nikhil Rao', 'Galaxy M12', 6, 'Anjali Singh'), ('Anita Joshi', 'Galaxy Z Flip', 15, 'Deepika Nair')]\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Find the names of customers who bought a mobile during its discount period, along with the mobile model, discount percentage, and the name of the staff who handled the sale.', 'result': \"[('Rahul Sharma', 'Galaxy S21', 10, 'Anjali Singh'), ('Priya Mehta', 'Galaxy A52', 5, 'Ravi Kumar'), ('Aman Verma', 'Galaxy Z Flip', 15, 'Anjali Singh'), ('Sneha Reddy', 'Galaxy S21', 7, 'Suman Tiwari'), ('Karan Patel', 'Galaxy S22', 10, 'Mohit Jain'), ('Meena Iyer', 'Galaxy A52', 12, 'Ravi Kumar'), ('Nikhil Rao', 'Galaxy M12', 6, 'Anjali Singh'), ('Anita Joshi', 'Galaxy Z Flip', 15, 'Deepika Nair')]\"}\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create the fixed chain\n",
    "new_chain = CleaningSQLDatabaseChain.from_llm(\n",
    "    llm=llm, \n",
    "    db=db, \n",
    "    verbose=True, \n",
    "    prompt=few_shot_prompt\n",
    ")\n",
    "\n",
    "# Test it\n",
    "result = new_chain(\"Find the names of customers who bought a mobile during its discount period, along with the mobile model, discount percentage, and the name of the staff who handled the sale.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "984623e7-1761-4bb8-ac59-94f25f40b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CleaningSQLDatabaseChain chain...\u001b[0m\n",
      "Raw LLM Response: Question: List all sales where the discount period had expired before the sale date, along with details of the mobile, discount period, and customer name.\n",
      "SQLQuery: SELECT s.sale_date, c.name, m.model, d.discount_percent, d.start_date, d.end_date FROM sales s JOIN mobiles m ON s.mobile_id = m.mobile_id JOIN customers c ON s.customer_id = c.customer_id JOIN discounts d ON m.mobile_id = d.mobile_id WHERE d.end_date < s.sale_date;\n",
      "SQLResult: Result of the SQL query\n",
      "Answer: []\n",
      "Cleaned SQL: SELECT s.sale_date, c.name, m.model, d.discount_percent, d.start_date, d.end_date FROM sales s JOIN mobiles m ON s.mobile_id = m.mobile_id JOIN customers c ON s.customer_id = c.customer_id JOIN discounts d ON m.mobile_id = d.mobile_id WHERE d.end_date < s.sale_date;\n",
      "SQL Result: \n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'List all sales where the discount period had expired before the sale date, along with details of the mobile, discount period, and customer name.', 'result': ''}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result1 = new_chain(\"List all sales where the discount period had expired before the sale date, along with details of the mobile, discount period, and customer name.\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75829b81-d884-4b37-a154-ddb24a555174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CleaningSQLDatabaseChain chain...\u001b[0m\n",
      "Raw LLM Response: Question: List the staff member who handled the highest total sales revenue along with the total revenue.\n",
      "SQLQuery: SELECT s.name, SUM(sa.total_amount) AS total_revenue FROM sales sa JOIN staff s ON sa.staff_id = s.staff_id GROUP BY s.staff_id, s.name ORDER BY total_revenue DESC LIMIT 1;\n",
      "SQLResult: Result of the SQL query\n",
      "Answer: [('Anjali Singh', Decimal('139250'))]\n",
      "Cleaned SQL: SELECT s.name, SUM(sa.total_amount) AS total_revenue FROM sales sa JOIN staff s ON sa.staff_id = s.staff_id GROUP BY s.staff_id, s.name ORDER BY total_revenue DESC LIMIT 1;\n",
      "SQL Result: [('Anjali Singh', Decimal('203170'))]\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'List the staff member who handled the highest total sales revenue along with the total revenue.', 'result': \"[('Anjali Singh', Decimal('203170'))]\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result2 = new_chain(\"List the staff member who handled the highest total sales revenue along with the total revenue.\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef191b7-7d42-43a6-bb07-183135e6efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
